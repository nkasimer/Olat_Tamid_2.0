{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to automatically make diacritical corrections in Hebrew text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines letters and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleph_bet = ['א','ב','ג','ד','ה','ו','ז','ח','ט','י','כ','ך','ל','מ','ם',\n",
    "             'נ','ן','ס','ע','פ','ף','צ','ק','ר','ש','ת','װ','ױ','ײ','יִ',\n",
    "             'ﬡ','ﬢ','ﬣ','ﬤ','ﬥ','ﬦ','ﬧ','ﬨ','שׁ','שׂ','שּׁ','שּׂ','אַ','אָ',\n",
    "             'גּ','דּ','הּ','וּ','זּ','טּ','יּ','ךּ','כּ','לּ','מּ','נּ','סּ','ףּ',\n",
    "             'פּ','צּ','שּ','תּ','וֹ','בֿ','כֿ','פֿ','ﭏ','בּ', 'קּ']\n",
    "\n",
    "cant = ['֑','֒','֓','֔','֕','֖','֗','֘','֙','֚','֛','֜',\n",
    "             '֝','֞','֠','֡','֢','֣','֤','֥','֦','֧','֨','֩','֪','֫','֬','֭','֯','׃']\n",
    "\n",
    "vowel = ['ְ','ֱ','ֲ','ֳ','ִ','ֵ','ֶ','ַ','ָ','ֹ','ֺ','ֻ','ּ','ֽ','־','ֿ','ׁ','ׂ','ׄ','ׅ','ׇ']\n",
    "\n",
    "letter_with_dagesh = ['שּׁ','שּׂ','גּ','דּ','זּ','טּ','יּ','כּ','לּ','מּ','נּ','סּ','פּ','צּ','שּ','תּ','בּ','קּ']\n",
    "rafe = 'ֿ'\n",
    "shva = vowel[0]\n",
    "chataf_vowels = vowel[1:4]\n",
    "short_vowels = [vowel[4],vowel[6],vowel[7],vowel[11],vowel[20]]\n",
    "long_vowels = ['וֹ','וּ', vowel[5], vowel[8], aleph_bet[9], 'ֹ']\n",
    "vowels_limited = chataf_vowels+short_vowels+long_vowels\n",
    "dagesh = 'ּ'\n",
    "\n",
    "gutterals = ['א','ה','ח','ע','ר' ,'ﬡ','ﬣ','ﬧ']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "shem = 'יהוה'\n",
    "shem_vowels = 'יְהֹוָה'\n",
    "yy_vowels = aleph_bet[9]+vowel[0]+aleph_bet[9]+vowel[8]\n",
    "\n",
    "kal = aleph_bet[52] + vowel[8] + aleph_bet[12]\n",
    "khal = aleph_bet[10] + vowel[8] + aleph_bet[12]\n",
    "kol_maqqaf = aleph_bet[52] + vowel[20] + aleph_bet[12] + '־'\n",
    "khol_maqqaf = aleph_bet[10] + vowel[20] + aleph_bet[12] + '־'\n",
    "kol_space = aleph_bet[52] + vowel[20] + aleph_bet[12] + ' '\n",
    "khol_space = aleph_bet[10] + vowel[20] + aleph_bet[12] + ' '\n",
    "\n",
    "et = 'אֶת'\n",
    "ve_et = 'וְאֶת'\n",
    "space_et_space = ' ' + 'אֶת' + ' '\n",
    "space_ve_et_space = ' ' + 'וְאֶת' + ' '\n",
    "et_maqqaf = ' ' + 'אֶת' + '־'\n",
    "ve_et_maqqaf = ' ' + 'וְאֶת' + '־'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "shva_exceptions = ['שְׁתֵּי','שְׁתָּיִם','שְׁתַּיִם','שְׁנִַים','שְׁנֵי','שְׁתֵּים','שְׁנֵים']\n",
    "battim = 'בָּתִּים'\n",
    "vattim = 'בָתִּים'\n",
    "kamatz_katan_exceptions = [battim, vattim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strips vowels and cantelation marks from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop and vowels\n",
    "def nonalpha_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter.isalpha() == True:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop but not vowels\n",
    "def trop_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter not in cant:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts Shem-Havaya to double-yud while preserving cantelation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shem_converter(word):\n",
    "    prefix = ''\n",
    "    if word[0] != aleph_bet[9]:\n",
    "        prefix = prefix + word[0]\n",
    "        if word[1].isalpha() == False:\n",
    "            prefix = prefix + word[1]\n",
    "            if word[2].isalpha() == False:\n",
    "                prefix = prefix + word[2]\n",
    "    no_prefix_word = word[len(prefix):]\n",
    "\n",
    "    if len(prefix) > 0:\n",
    "        yud1 = aleph_bet[9]\n",
    "    else:\n",
    "        yud1 = aleph_bet[9]+vowel[0]\n",
    "\n",
    "    yud2 = aleph_bet[9]+vowel[8]\n",
    "\n",
    "    cant_marks = []\n",
    "\n",
    "    for character in no_prefix_word:\n",
    "        if character in cant:\n",
    "            cant_marks.append(character)\n",
    "    if len(cant_marks) == 0:\n",
    "        new_shem = prefix + yud1 + yud2\n",
    "    elif len(cant_marks) == 1:\n",
    "        new_shem = prefix + yud1 + yud2 + cant_marks[0]\n",
    "    elif len(cant_marks) == 2:\n",
    "        new_shem = prefix + yud1 + cant_marks[0] + yud2 + cant_marks[1]\n",
    "\n",
    "    return new_shem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates new paragraph with double-yud in place of Shem Havaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_shem(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if shem in nonalpha_remover(word):\n",
    "            double_yud = shem_converter(word)\n",
    "            par_list[index] = double_yud\n",
    "\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use https://he.wikisource.org/wiki/%D7%9E%D7%A7%D7%A8%D7%90 for testing texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan and maqqaf in \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs and kamatz katans, it shouldn't make it less useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_exception(word):\n",
    "    if word[-1] != aleph_bet[12]:\n",
    "        return True\n",
    "    elif aleph_bet[9] in word:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    #returns \"true\" if the word is a likely false positive for the word \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kol_kamatz_katan(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    #Paragraph is now split into words\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if (kal in word or khal in word) and kamatz_exception(word) == False:\n",
    "            split_word = word.split(vowel[8])\n",
    "            word = vowel[20].join(split_word)\n",
    "            par_list[index] = word\n",
    "            #If \"k(h)al\" appears in a word, change it to a kamatz katan\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    #Put paragraph back together\n",
    "    if kol_space in new_par: \n",
    "        new_par_split = new_par.split(kol_space)\n",
    "        new_par = kol_maqqaf.join(new_par_split)\n",
    "    if khol_space in new_par:\n",
    "        new_par_split = new_par.split(khol_space)\n",
    "        new_par = khol_maqqaf.join(new_par_split)\n",
    "    #Previous if-statements swap a space following \"kol\" to a maqqaf\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a Maqqaf after \"et\" (when it has a segol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs, this shouldn't be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_fixer(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    if et in par_list:\n",
    "        new_par_split = paragraph.split(space_et_space)\n",
    "        new_paragraph = et_maqqaf.join(new_par_split)\n",
    "        new_par_split = new_paragraph.split(space_ve_et_space)\n",
    "        new_paragraph = ve_et_maqqaf.join(new_par_split)\n",
    "    else:\n",
    "        new_paragraph = paragraph\n",
    "    return new_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan in common kamatz-katan words and situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have kamatz katans, this shouldn't be too much of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "chakhma = 'חָכְמָה'\n",
    "chokhma = 'חׇכְמָה'\n",
    "karban = 'קָרְבַּן'\n",
    "korban = 'קׇרְבַּן'\n",
    "kareinu = 'קָרְאֵֽנוּ'\n",
    "koreinu = 'קׇרְאֵֽנוּ'\n",
    "karbe_ = 'קָרְבְּ'\n",
    "korbe_ = 'קׇרְבְּ'\n",
    "kadshe_ = 'קָדְשְׁ'\n",
    "kodshe_ = 'קׇדְשְׁ'\n",
    "kadashim = 'קׇדָשִׁים'\n",
    "kodashim = 'קׇדָשִׁים'\n",
    "\n",
    "words_to_fix = [chakhma, karban, kareinu, karbe_, kadshe_, kadashim]\n",
    "corrected_words = [chokhma, korban, koreinu, korbe_, kodshe_, kodashim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan_adder(word):    \n",
    "    #prevents script from erroneously fixing false positives\n",
    "    nt_word = trop_remover(word)\n",
    "\n",
    "    for index in range(0,len(kamatz_katan_exceptions)):\n",
    "        if kamatz_katan_exceptions[index] in nt_word:\n",
    "            return word\n",
    "    \n",
    "    for index in range(1,len(word)-2):\n",
    "        if word[index] == vowel[8]:\n",
    "            i = index\n",
    "            while word[i] not in aleph_bet:\n",
    "                i = i+1\n",
    "            next_consonant = word[i]\n",
    "            if next_consonant in letter_with_dagesh:\n",
    "                word = word[:index]+vowel[20]+word[index:]\n",
    "            \n",
    "            i = index+1\n",
    "            while word[i] not in vowels_limited:\n",
    "                i = i+1\n",
    "                if i>len(word)-1:\n",
    "                    return word\n",
    "            next_vowel = word[i]\n",
    "            if next_vowel == chataf_vowels[2] and next_consonant in gutterals:\n",
    "                word = word[:index]+vowel[20]+word[index:]\n",
    "    \n",
    "    #add kamatz katan if next vowel is chataf-kamatz and the next consonant is a gutteral\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan(paragraph):\n",
    "    #This goes through the list of common words with kamatz katan (besides \"kol\")\n",
    "    #and corrects them if they are present.\n",
    "    #This list can be added to as needed.\n",
    "    for index in range(len(words_to_fix)):\n",
    "        paragraph = paragraph.replace(words_to_fix[index],corrected_words[index])\n",
    "    par_list = paragraph.split()\n",
    "    \n",
    "    #Calls the kamatz_katan_adder for each word in paragraph, if that word has a kamatz at all\n",
    "    for index in range(len(par_list)-1):\n",
    "        if vowel[8] in par_list[index]:\n",
    "            par_list[index] = kamatz_katan_adder(par_list[index])\n",
    "    paragraph = ' '.join(par_list)\n",
    "    return paragraph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kamatz katan adder needs to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = 'יֹ֭שֵׁב בְּסֵ֣תֶר עֶלְי֑וֹן בְּצֵ֥ל שַׁ֝דַּ֗י יִתְלוֹנָֽן׃ אֹמַ֗ר לַֽ֭יהוָה מַחְסִ֣י וּמְצוּדָתִ֑י אֱ֝לֹהַ֗י אֶבְטַח־בּֽוֹ׃ כִּ֤י ה֣וּא יַ֭צִּֽילְךָ מִפַּ֥ח יָק֗וּשׁ מִדֶּ֥בֶר הַוּֽוֹת׃ בְּאֶבְרָת֨וֹ ׀ יָ֣סֶךְ לָ֭ךְ וְתַֽחַת־כְּנָפָ֣יו תֶּחְסֶ֑ה צִנָּ֖ה וְֽסֹחֵרָ֣ה אֲמִתּֽוֹ׃ לֹא־תִ֭ירָא מִפַּ֣חַד לָ֑יְלָה מֵ֝חֵ֗ץ יָע֥וּף יוֹמָֽם׃ מִ֭דֶּבֶר בָּאֹ֣פֶל יַהֲלֹ֑ךְ מִ֝קֶּ֗טֶב יָשׁ֥וּד צָהֳרָֽיִם׃ יִפֹּ֤ל מִצִּדְּךָ֨ ׀ אֶ֗לֶף וּרְבָבָ֥ה מִימִינֶ֑ךָ אֵ֝לֶ֗יךָ לֹ֣א יִגָּֽשׁ׃ רַ֭ק בְּעֵינֶ֣יךָ תַבִּ֑יט וְשִׁלֻּמַ֖ת רְשָׁעִ֣ים תִּרְאֶֽה׃ כִּֽי־אַתָּ֣ה יְהוָ֣ה מַחְסִ֑י עֶ֝לְי֗וֹן שַׂ֣מְתָּ מְעוֹנֶֽךָ׃ לֹֽא־תְאֻנֶּ֣ה אֵלֶ֣יךָ רָעָ֑ה וְ֝נֶ֗גַע לֹא־יִקְרַ֥ב בְּאָהֳלֶֽךָ׃ כִּ֣י מַ֭לְאָכָיו יְצַוֶּה־לָּ֑ךְ לִ֝שְׁמָרְךָ֗ בְּכָל־דְּרָכֶֽיךָ׃ עַל־כַּפַּ֥יִם יִשָּׂא֑וּנְךָ פֶּן־תִּגֹּ֖ף בָּאֶ֣בֶן רַגְלֶֽךָ׃ עַל־שַׁ֣חַל וָפֶ֣תֶן תִּדְרֹ֑ךְ תִּרְמֹ֖ס כְּפִ֣יר וְתַנִּֽין׃ כִּ֤י בִ֣י חָ֭שַׁק וַאֲפַלְּטֵ֑הוּ אֲ֝שַׂגְּבֵ֗הוּ כִּֽי־יָדַ֥ע שְׁמִֽי׃ יִקְרָאֵ֨נִי ׀ וְֽאֶעֱנֵ֗הוּ עִמּֽוֹ־אָנֹכִ֥י בְצָרָ֑ה אֲ֝חַלְּצֵ֗הוּ וַֽאֲכַבְּדֵֽהוּ׃ אֹ֣רֶךְ יָ֭מִים אַשְׂבִּיעֵ֑הוּ וְ֝אַרְאֵ֗הוּ בִּֽישׁוּעָתִֽי׃'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'יֹ֭שֵׁב בְּסֵ֣תֶר עֶלְי֑וֹן בְּצֵ֥ל שַׁ֝דַּ֗י יִתְלוֹנָֽן׃ אֹמַ֗ר לַֽ֭יהוָה מַחְסִ֣י וּמְצוּדָתִ֑י אֱ֝לֹהַ֗י אֶבְטַח־בּֽוֹ׃ כִּ֤י ה֣וּא יַ֭צִּֽילְךָ מִפַּ֥ח יָק֗וּשׁ מִדֶּ֥בֶר הַוּֽוֹת׃ בְּאֶבְרָת֨וֹ ׀ יָ֣סֶךְ לָ֭ךְ וְתַֽחַת־כְּנָפָ֣יו תֶּחְסֶ֑ה צִנָּ֖ה וְֽסֹחֵרָ֣ה אֲמִתּֽוֹ׃ לֹא־תִ֭ירָא מִפַּ֣חַד לָ֑יְלָה מֵ֝חֵ֗ץ יָע֥וּף יוֹמָֽם׃ מִ֭דֶּבֶר בָּאֹ֣פֶל יַהֲלֹ֑ךְ מִ֝קֶּ֗טֶב יָשׁ֥וּד צׇׇׇׇׇׇׇׇָהֳרָֽיִם׃ יִפֹּ֤ל מִצִּדְּךָ֨ ׀ אֶ֗לֶף וּרְבָבָ֥ה מִימִינֶ֑ךָ אֵ֝לֶ֗יךָ לֹ֣א יִגָּֽשׁ׃ רַ֭ק בְּעֵינֶ֣יךָ תַבִּ֑יט וְשִׁלֻּמַ֖ת רְשָׁעִ֣ים תִּרְאֶֽה׃ כִּֽי־אַתָּ֣ה יְהוָ֣ה מַחְסִ֑י עֶ֝לְי֗וֹן שַׂ֣מְתָּ מְעוֹנֶֽךָ׃ לֹֽא־תְאֻנֶּ֣ה אֵלֶ֣יךָ רָעָ֑ה וְ֝נֶ֗גַע לֹא־יִקְרַ֥ב בְּאׇׇׇׇׇׇׇָהֳלֶֽךָ׃ כִּ֣י מַ֭לְאָכָיו יְצַוֶּה־לָּ֑ךְ לִ֝שְׁמָרְךָ֗ בְּכָל־דְּרָכֶֽיךָ׃ עַל־כַּפַּ֥יִם יִשָּׂא֑וּנְךָ פֶּן־תִּגֹּ֖ף בָּאֶ֣בֶן רַגְלֶֽךָ׃ עַל־שַׁ֣חַל וָפֶ֣תֶן תִּדְרֹ֑ךְ תִּרְמֹ֖ס כְּפִ֣יר וְתַנִּֽין׃ כִּ֤י בִ֣י חָ֭שַׁק וַאֲפַלְּטֵ֑הוּ אֲ֝שַׂגְּבֵ֗הוּ כִּֽי־יָדַ֥ע שְׁמִֽי׃ יִקְרָאֵ֨נִי ׀ וְֽאֶעֱנֵ֗הוּ עִמּֽוֹ־אָנֹכִ֥י בְצָרָ֑ה אֲ֝חַלְּצֵ֗הוּ וַֽאֲכַבְּדֵֽהוּ׃ אֹ֣רֶךְ יָ֭מִים אַשְׂבִּיעֵ֑הוּ וְ֝אַרְאֵ֗הוּ בִּֽישׁוּעָתִֽי׃'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kamatz_katan(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks shva na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserts a rafe to mark a shva na'\n",
    "def na_marker(paragraph,index):\n",
    "    if paragraph[index-1] == rafe or paragraph[index+1] == rafe:\n",
    "        return paragraph\n",
    "        #does nothing, if the shva is already marked with a rafe\n",
    "    else:\n",
    "        par_start = paragraph[:index]\n",
    "        par_end = paragraph[index:]\n",
    "        new_par = par_start+rafe+par_end\n",
    "        return new_par\n",
    "        #adds a rafe over the input letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determines what shvas are na' in a word, and calls the program to mark them\n",
    "def shva_na_function(word):\n",
    "    nt_word = trop_remover(word)\n",
    "    #this skips instances of shem hashem\n",
    "    if nt_word == shem_vowels or nt_word == yy_vowels:\n",
    "        return word\n",
    "    if nt_word in shva_exceptions:\n",
    "        return word\n",
    "    for index in range(1,len(word)-2):\n",
    "        i = index\n",
    "        if word[index] != shva:\n",
    "            continue\n",
    "            #this doesn't bother with the loop if the letter isn't a shva\n",
    "            \n",
    "        while word[i] not in aleph_bet:\n",
    "            i = i-1\n",
    "        previous_consonant = word[i]\n",
    "        #if the previous consonant is the beginning of the word, the shva is na'\n",
    "        if i == 0:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        #if the previous consonant has a dagesh, the shva must be na'\n",
    "        if previous_consonant in letter_with_dagesh:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        if word[i+1] == dagesh:\n",
    "            word = na_marker(word,index)\n",
    "\n",
    "        #determines the previous vowel\n",
    "        i = index\n",
    "        while word[i] not in vowels_limited:\n",
    "            i = i-1\n",
    "            if i == 0:\n",
    "                return word\n",
    "        previous_vowel = word[i]\n",
    "        #if the previous vowel is a shva, the current shva is na'\n",
    "        if previous_vowel == shva:\n",
    "            word = na_marker(word,index)\n",
    "        if previous_vowel in long_vowels:\n",
    "            word = na_marker(word,index)    \n",
    "        \n",
    "        #a shva following a long vowel is na', unless the long vowel is word-initial shuruk\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls the shva_na_function for each word in the input paragraph\n",
    "def shva_na_converter(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        par_list[index] = shva_na_function(word)\n",
    "    new_par = ' '.join(par_list)\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Paragraph through all converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_converter(paragraph):\n",
    "    #Comment out components of the script you don't want to run\n",
    "    paragraph = convert_shem(paragraph)\n",
    "    paragraph = kol_kamatz_katan(paragraph)\n",
    "    paragraph = et_fixer(paragraph)\n",
    "    paragraph = kamatz_katan(paragraph)\n",
    "    paragraph = shva_na_converter(paragraph)\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'יֹ֭שֵׁב בְּֿסֵ֣תֶר עֶלְי֑וֹן בְּֿצֵ֥ל שַׁ֝דַּ֗י יִתְלוֹנָֽן׃ אֹמַ֗ר לַֽייָ֭ מַחְסִ֣י וּמְצוּדָתִ֑י אֱ֝לֹהַ֗י אֶבְטַח־בּֽוֹ׃ כִּ֤י ה֣וּא יַ֭צִּֽילְֿךָ מִפַּ֥ח יָק֗וּשׁ מִדֶּ֥בֶר הַוּֽוֹת׃ בְּֿאֶבְרָת֨וֹ ׀ יָ֣סֶךְ לָ֭ךְ וְֿתַֽחַת־כְּֿנָפָ֣יו תֶּחְסֶ֑ה צִנָּ֖ה וְֽֿסֹחֵרָ֣ה אֲמִתּֽוֹ׃ לֹא־תִ֭ירָא מִפַּ֣חַד לָ֑יְֿלָה מֵ֝חֵ֗ץ יָע֥וּף יוֹמָֽם׃ מִ֭דֶּבֶר בָּאֹ֣פֶל יַהֲלֹ֑ךְ מִ֝קֶּ֗טֶב יָשׁ֥וּד צׇׇׇׇׇׇׇׇָהֳרָֽיִם׃ יִפֹּ֤ל מִצִּדְּֿךָ֨ ׀ אֶ֗לֶף וּרְבָבָ֥ה מִימִינֶ֑ךָ אֵ֝לֶ֗יךָ לֹ֣א יִגָּֽשׁ׃ רַ֭ק בְּֿעֵינֶ֣יךָ תַבִּ֑יט וְֿשִׁלֻּמַ֖ת רְֿשָׁעִ֣ים תִּרְאֶֽה׃ כִּֽי־אַתָּ֣ה יְיָ֣ מַחְסִ֑י עֶ֝לְי֗וֹן שַׂ֣מְתָּ מְֿעוֹנֶֽךָ׃ לֹֽא־תְֿאֻנֶּ֣ה אֵלֶ֣יךָ רָעָ֑ה וְֿ֝נֶ֗גַע לֹא־יִקְרַ֥ב בְּֿאׇׇׇׇׇׇׇָהֳלֶֽךָ׃ כִּ֣י מַ֭לְאָכָיו יְֿצַוֶּה־לָּ֑ךְ לִ֝שְׁמָרְֿךָ֗ בְּֿכׇל־דְּֿרָכֶֽיךָ׃ עַל־כַּפַּ֥יִם יִשָּׂא֑וּנְֿךָ פֶּן־תִּגֹּ֖ף בָּאֶ֣בֶן רַגְלֶֽךָ׃ עַל־שַׁ֣חַל וָפֶ֣תֶן תִּדְרֹ֑ךְ תִּרְמֹ֖ס כְּֿפִ֣יר וְֿתַנִּֽין׃ כִּ֤י בִ֣י חָ֭שַׁק וַאֲפַלְּֿטֵ֑הוּ אֲ֝שַׂגְּֿבֵ֗הוּ כִּֽי־יָדַ֥ע שְֿׁמִֽי׃ יִקְרָאֵ֨נִי ׀ וְֽֿאֶעֱנֵ֗הוּ עִמּֽוֹ־אָנֹכִ֥י בְֿצָרָ֑ה אֲ֝חַלְּֿצֵ֗הוּ וַֽאֲכַבְּֿדֵֽהוּ׃ אֹ֣רֶךְ יָ֭מִים אַשְׂבִּיעֵ֑הוּ וְֿ֝אַרְאֵ֗הוּ בִּֽישׁוּעָתִֽי׃'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_converter(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'olat_tamid_2.1.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    lines = list(infile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-191-e3078a8d6b9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mnew_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-187-4cf9152bcdfe>\u001b[0m in \u001b[0;36mtext_converter\u001b[1;34m(paragraph)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkol_kamatz_katan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0met_fixer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkamatz_katan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshva_na_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-173-dc6e4728c057>\u001b[0m in \u001b[0;36mkamatz_katan\u001b[1;34m(paragraph)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvowel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpar_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mpar_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkamatz_katan_adder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpar_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-22a56406495c>\u001b[0m in \u001b[0;36mkamatz_katan_adder\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mvowel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maleph_bet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mnext_consonant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(text_converter(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'olat_tamid_converted.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in new_lines:\n",
    "        if line != '':\n",
    "            if line[-1] != '\\n':\n",
    "                outfile.write(line + '\\n')\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "        else:\n",
    "            outfile.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
