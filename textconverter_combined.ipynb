{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to automatically make diacritical corrections in Hebrew text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines letters and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleph_bet = ['א','ב','ג','ד','ה','ו','ז','ח','ט','י','כ','ך','ל','מ','ם',\n",
    "             'נ','ן','ס','ע','פ','ף','צ','ק','ר','ש','ת','װ','ױ','ײ','יִ',\n",
    "             'ﬡ','ﬢ','ﬣ','ﬤ','ﬥ','ﬦ','ﬧ','ﬨ','שׁ','שׂ','שּׁ','שּׂ','אַ','אָ',\n",
    "             'גּ','דּ','הּ','וּ','זּ','טּ','יּ','ךּ','כּ','לּ','מּ','נּ','סּ','ףּ',\n",
    "             'פּ','צּ','שּ','תּ','וֹ','בֿ','כֿ','פֿ','ﭏ','בּ', 'קּ']\n",
    "\n",
    "cant = ['֑','֒','֓','֔','֕','֖','֗','֘','֙','֚','֛','֜',\n",
    "             '֝','֞','֠','֡','֢','֣','֤','֥','֦','֧','֨','֩','֪','֫','֬','֭','֯','׃']\n",
    "\n",
    "vowel = ['ְ','ֱ','ֲ','ֳ','ִ','ֵ','ֶ','ַ','ָ','ֹ','ֺ','ֻ','ּ','ֽ','־','ֿ','ׁ','ׂ','ׄ','ׅ','ׇ']\n",
    "\n",
    "letter_with_dagesh = ['שּׁ','שּׂ','גּ','דּ','זּ','טּ','יּ','כּ','לּ','מּ','נּ','סּ','פּ','צּ','שּ','תּ','בּ','קּ']\n",
    "rafe = 'ֿ'\n",
    "shva = vowel[0]\n",
    "chataf_vowels = vowel[1:4]\n",
    "short_vowels = [vowel[4],vowel[6],vowel[7],vowel[11],vowel[20]]\n",
    "long_vowels = ['וֹ','וּ', vowel[5], vowel[8], aleph_bet[9], 'ֹ']\n",
    "vowels_limited = chataf_vowels+short_vowels+long_vowels\n",
    "dagesh = 'ּ'\n",
    "\n",
    "gutterals = ['א','ה','ח','ע','ר' ,'ﬡ','ﬣ','ﬧ']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ֳ'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chataf_vowels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "shem = 'יהוה'\n",
    "shem_vowels = 'יְהֹוָה'\n",
    "yy_vowels = aleph_bet[9]+vowel[0]+aleph_bet[9]+vowel[8]\n",
    "\n",
    "kal = aleph_bet[52] + vowel[8] + aleph_bet[12]\n",
    "khal = aleph_bet[10] + vowel[8] + aleph_bet[12]\n",
    "kol_maqqaf = aleph_bet[52] + vowel[20] + aleph_bet[12] + '־'\n",
    "khol_maqqaf = aleph_bet[10] + vowel[20] + aleph_bet[12] + '־'\n",
    "kol_space = aleph_bet[52] + vowel[20] + aleph_bet[12] + ' '\n",
    "khol_space = aleph_bet[10] + vowel[20] + aleph_bet[12] + ' '\n",
    "\n",
    "et = 'אֶת'\n",
    "ve_et = 'וְאֶת'\n",
    "space_et_space = ' ' + 'אֶת' + ' '\n",
    "space_ve_et_space = ' ' + 'וְאֶת' + ' '\n",
    "et_maqqaf = ' ' + 'אֶת' + '־'\n",
    "ve_et_maqqaf = ' ' + 'וְאֶת' + '־'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "shva_exceptions = ['שְׁתֵּי','שְׁתָּיִם','שְׁתַּיִם','שְׁנִַים','שְׁנֵי','שְׁתֵּים','שְׁנֵים']\n",
    "battim = 'בָּתִּים'\n",
    "vattim = 'בָתִּים'\n",
    "kamatz_katan_exceptions = [battim, vattim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strips vowels and cantelation marks from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop and vowels\n",
    "def nonalpha_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter.isalpha() == True:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop but not vowels\n",
    "def trop_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter not in cant:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts Shem-Havaya to double-yud while preserving cantelation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shem_converter(word):\n",
    "    prefix = ''\n",
    "    if word[0] != aleph_bet[9]:\n",
    "        prefix = prefix + word[0]\n",
    "        if word[1].isalpha() == False:\n",
    "            prefix = prefix + word[1]\n",
    "            if word[2].isalpha() == False:\n",
    "                prefix = prefix + word[2]\n",
    "    no_prefix_word = word[len(prefix):]\n",
    "\n",
    "    if len(prefix) > 0:\n",
    "        yud1 = aleph_bet[9]\n",
    "    else:\n",
    "        yud1 = aleph_bet[9]+vowel[0]\n",
    "\n",
    "    yud2 = aleph_bet[9]+vowel[8]\n",
    "\n",
    "    cant_marks = []\n",
    "\n",
    "    for character in no_prefix_word:\n",
    "        if character in cant:\n",
    "            cant_marks.append(character)\n",
    "    if len(cant_marks) == 0:\n",
    "        new_shem = prefix + yud1 + yud2\n",
    "    elif len(cant_marks) == 1:\n",
    "        new_shem = prefix + yud1 + yud2 + cant_marks[0]\n",
    "    elif len(cant_marks) == 2:\n",
    "        new_shem = prefix + yud1 + cant_marks[0] + yud2 + cant_marks[1]\n",
    "\n",
    "    return new_shem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates new paragraph with double-yud in place of Shem Havaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_shem(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if shem in nonalpha_remover(word):\n",
    "            double_yud = shem_converter(word)\n",
    "            par_list[index] = double_yud\n",
    "\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use https://he.wikisource.org/wiki/%D7%9E%D7%A7%D7%A8%D7%90 for testing texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan and maqqaf in \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs and kamatz katans, it shouldn't make it less useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_exception(word):\n",
    "    if word[-1] != aleph_bet[12]:\n",
    "        return True\n",
    "    elif aleph_bet[9] in word:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    #returns \"true\" if the word is a likely false positive for the word \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kol_kamatz_katan(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    #Paragraph is now split into words\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if (kal in word or khal in word) and kamatz_exception(word) == False:\n",
    "            split_word = word.split(vowel[8])\n",
    "            word = vowel[20].join(split_word)\n",
    "            par_list[index] = word\n",
    "            #If \"k(h)al\" appears in a word, change it to a kamatz katan\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    #Put paragraph back together\n",
    "    if kol_space in new_par: \n",
    "        new_par_split = new_par.split(kol_space)\n",
    "        new_par = kol_maqqaf.join(new_par_split)\n",
    "    if khol_space in new_par:\n",
    "        new_par_split = new_par.split(khol_space)\n",
    "        new_par = khol_maqqaf.join(new_par_split)\n",
    "    #Previous if-statements swap a space following \"kol\" to a maqqaf\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a Maqqaf after \"et\" (when it has a segol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs, this shouldn't be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_fixer(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    if et in par_list:\n",
    "        new_par_split = paragraph.split(space_et_space)\n",
    "        new_paragraph = et_maqqaf.join(new_par_split)\n",
    "        new_par_split = new_paragraph.split(space_ve_et_space)\n",
    "        new_paragraph = ve_et_maqqaf.join(new_par_split)\n",
    "    else:\n",
    "        new_paragraph = paragraph\n",
    "    return new_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan in common kamatz-katan words and situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have kamatz katans, this shouldn't be too much of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chakhma = 'חָכְמָה'\n",
    "chokhma = 'חׇכְמָה'\n",
    "karban = 'קָרְבַּן'\n",
    "korban = 'קׇרְבַּן'\n",
    "kareinu = 'קָרְאֵֽנוּ'\n",
    "koreinu = 'קׇרְאֵֽנוּ'\n",
    "karbe_ = 'קָרְבְּ'\n",
    "korbe_ = 'קׇרְבְּ'\n",
    "kadshe_ = 'קָדְשְׁ'\n",
    "kodshe_ = 'קׇדְשְׁ'\n",
    "kadashim = 'קׇדָשִׁים'\n",
    "kodashim = 'קׇדָשִׁים'\n",
    "\n",
    "words_to_fix = [chakhma, karban, kareinu, karbe_, kadshe_, kadashim]\n",
    "corrected_words = [chokhma, korban, koreinu, korbe_, kodshe_, kodashim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan_adder(word):    \n",
    "    #prevents script from erroneously fixing false positives\n",
    "    nt_word = trop_remover(word)\n",
    "    for index in range(0,index(kamatz_katan_exceptions)):\n",
    "        if kamatz_katan_exceptions[index] in nt_word:\n",
    "            return word\n",
    "    \n",
    "    for index in range(1,len(word)-2):\n",
    "        if word[index] == vowel[8]:\n",
    "            i = index\n",
    "            while word[i] not in aleph_bet:\n",
    "                i = i+1\n",
    "            next_consonant = word[i]\n",
    "            if next_consonant in letter_with_dagesh:\n",
    "                word[index] = vowel[20]\n",
    "                \n",
    "            while word[i] not in vowels_limited:\n",
    "                i = i+1\n",
    "            next_vowel = word[i]\n",
    "            if next_vowel == chataf_vowels[2] and next_consonant in gutterals:\n",
    "                word[index] = vowel[20]\n",
    "    \n",
    "    #add kamatz katan if next vowel is chataf-kamatz and the next consonant is a gutteral\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan(paragraph):\n",
    "    #This goes through the list of common words with kamatz katan (besides \"kol\")\n",
    "    #and corrects them if they are present.\n",
    "    #This list can be added to as needed.\n",
    "    for index in range(len(words_to_fix)):\n",
    "        paragraph = paragraph.replace(words_to_fix[index],corrected_words[index])\n",
    "    par_list = paragraph.split()\n",
    "    \n",
    "    #Calls the kamatz_katan_adder for each word in paragraph, if that word has a kamatz at all\n",
    "    for index in range(len(par_list)):\n",
    "        if vowel[8] in par_list[index]:\n",
    "            par_list[index] = kamatz_katan_adder(par_list[index])\n",
    "\n",
    "                #paragraph = [paragraph[0:index]+vowel[20]+paragraph[index+1:len(paragraph)]]\n",
    "    paragraph = ' '.join(par_list)\n",
    "    return paragraph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kamatz katan adder needs to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks shva na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserts a rafe to mark a shva na'\n",
    "def na_marker(paragraph,index):\n",
    "    if paragraph[index-1] == rafe or paragraph[index+1] == rafe:\n",
    "        return paragraph\n",
    "        #does nothing, if the shva is already marked with a rafe\n",
    "    else:\n",
    "        par_start = paragraph[:index]\n",
    "        par_end = paragraph[index:]\n",
    "        new_par = par_start+rafe+par_end\n",
    "        return new_par\n",
    "        #adds a rafe over the input letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determines what shvas are na' in a word, and calls the program to mark them\n",
    "def shva_na_function(word):\n",
    "    nt_word = trop_remover(word)\n",
    "    #this skips instances of shem hashem\n",
    "    if nt_word == shem_vowels or nt_word == yy_vowels:\n",
    "        return word\n",
    "    if nt_word in shva_exceptions:\n",
    "        return word\n",
    "    for index in range(1,len(word)-2):\n",
    "        i = index\n",
    "        if word[index] != shva:\n",
    "            continue\n",
    "            #this doesn't bother with the loop if the letter isn't a shva\n",
    "            \n",
    "        while word[i] not in aleph_bet:\n",
    "            i = i-1\n",
    "        previous_consonant = word[i]\n",
    "        #if the previous consonant is the beginning of the word, the shva is na'\n",
    "        if i == 0:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        #if the previous consonant has a dagesh, the shva must be na'\n",
    "        if previous_consonant in letter_with_dagesh:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        \n",
    "        #determines the previous vowel\n",
    "        while word[i] not in vowels_limited:\n",
    "            i = i-1\n",
    "        previous_vowel = word[i]\n",
    "        #if the previous vowel is a shva, the current shva is na'\n",
    "        if previous_vowel == shva:\n",
    "            word = na_marker(word,index)\n",
    "        if previous_vowel in long_vowels and i != 0:\n",
    "            word = na_marker(word,index)    \n",
    "        \n",
    "        #a shva following a long vowel is na', unless the long vowel is word-initial shuruk\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls the shva_na_function for each word in the input paragraph\n",
    "def shva_na_converter(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        par_list[index] = shva_na_function(word)\n",
    "    new_par = ' '.join(par_list)\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = 'בַּחֹ֤דֶשׁ הָרִאשׁוֹן֙ הוּא־חֹ֣דֶשׁ נִיסָ֔ן בִּשְׁנַת֙ שְׁתֵּ֣ים עֶשְׂרֵ֔ה לַמֶּ֖לֶךְ אֲחַשְׁוֵר֑וֹשׁ הִפִּ֣יל פּוּר֩ ה֨וּא הַגּוֹרָ֜ל לִפְנֵ֣י הָמָ֗ן מִיּ֧וֹם ׀ לְי֛וֹם וּמֵחֹ֛דֶשׁ לְחֹ֥דֶשׁ שְׁנֵים־עָשָׂ֖ר הוּא־חֹ֥דֶשׁ אֲדָֽר׃'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'בַּחֹ֤דֶשׁ הָרִאשׁוֹן֙ הוּא־חֹ֣דֶשׁ נִיסָ֔ן בִּשְׁנַת֙ שְׁתֵּ֣ים עֶשְׂרֵ֔ה לַמֶּ֖לֶךְ אֲחַשְׁוֵר֑וֹשׁ הִפִּ֣יל פּוּר֩ ה֨וּא הַגּוֹרָ֜ל לִפְנֵ֣י הָמָ֗ן מִיּ֧וֹם ׀ לְֿי֛וֹם וּמֵחֹ֛דֶשׁ לְֿחֹ֥דֶשׁ שְֿׁנֵים־עָשָׂ֖ר הוּא־חֹ֥דֶשׁ אֲדָֽר׃'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shva_na_converter(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Paragraph through all converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_converter(paragraph):\n",
    "    #Comment out components of the script you don't want to run\n",
    "    paragraph = convert_shem(paragraph)\n",
    "    paragraph = kol_kamatz_katan(paragraph)\n",
    "    paragraph = et_fixer(paragraph)\n",
    "    paragraph = kamatz_katan(paragraph)\n",
    "    paragraph = shva_na_converter(paragraph)\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'olat_tamid_2.1.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    lines = list(infile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'new_paragraph' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-e3078a8d6b9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mnew_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-4cf9152bcdfe>\u001b[0m in \u001b[0;36mtext_converter\u001b[1;34m(paragraph)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkol_kamatz_katan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0met_fixer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkamatz_katan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshva_na_converter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-266e755120e8>\u001b[0m in \u001b[0;36mkamatz_katan\u001b[1;34m(paragraph)\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mnew_paragraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvowel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#corrects a potential kamatz katan false positive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mnew_paragraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_paragraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbattim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mnew_paragraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_paragraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvottim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvattim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_paragraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'new_paragraph' referenced before assignment"
     ]
    }
   ],
   "source": [
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(text_converter(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'olat_tamid_converted.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in new_lines:\n",
    "        if line != '':\n",
    "            if line[-1] != '\\n':\n",
    "                outfile.write(line + '\\n')\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "        else:\n",
    "            outfile.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
