{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replaces the Shem Havaya from Tanakh, replaces with double yud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hebrew Glyphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleph_bet = ['א','ב','ג','ד','ה','ו','ז','ח','ט','י','כ','ך','ל','מ','ם',\n",
    "             'נ','ן','ס','ע','פ','ף','צ','ק','ר','ש','ת','װ','ױ','ײ','יִ',\n",
    "             'ﬡ','ﬢ','ﬣ','ﬤ','ﬥ','ﬦ','ﬧ','ﬨ','שׁ','שׂ','שּׁ','שּׂ','אַ','אָ',\n",
    "             'גּ','דּ','הּ','וּ','זּ','טּ','יּ','ךּ','כּ','לּ','מּ','נּ','סּ','ףּ',\n",
    "             'פּ','צּ','שּ','תּ','וֹ','בֿ','כֿ','פֿ','ﭏ']\n",
    "\n",
    "cant = ['֑','֒','֓','֔','֕','֖','֗','֘','֙','֚','֛','֜',\n",
    "             '֝','֞','֠','֡','֢','֣','֤','֥','֦','֧','֨','֩','֪','֫','֬','֭','֯','׃']\n",
    "\n",
    "vowel = ['ְ','ֱ','ֲ','ֳ','ִ','ֵ','ֶ','ַ','ָ','ֹ','ֺ','ֻ','ּ','ֽ','־','ֿ','ׁ','ׂ','ׄ','ׅ','ׇ']\n",
    "\n",
    "\n",
    "shem = 'יהוה'\n",
    "\n",
    "kal = aleph_bet[52] + vowel[8] + aleph_bet[12]\n",
    "khal = aleph_bet[10] + vowel[8] + aleph_bet[12]\n",
    "kol_maqqaf = aleph_bet[52] + vowel[20] + aleph_bet[12] + '־'\n",
    "khol_maqqaf = aleph_bet[10] + vowel[20] + aleph_bet[12] + '־'\n",
    "kol_space = aleph_bet[52] + vowel[20] + aleph_bet[12] + ' '\n",
    "khol_space = aleph_bet[10] + vowel[20] + aleph_bet[12] + ' '\n",
    "\n",
    "et = 'אֶת'\n",
    "ve_et = 'וְאֶת'\n",
    "space_et_space = ' ' + 'אֶת' + ' '\n",
    "space_ve_et_space = ' ' + 'וְאֶת' + ' '\n",
    "et_maqqaf = ' ' + 'אֶת' + '־'\n",
    "ve_et_maqqaf = ' ' + 'וְאֶת' + '־'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Strips vowels and cantelation marks from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonalpha_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter.isalpha() == True:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts Shem-Havaya to double-yud while preserving cantelation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shem_converter(word):\n",
    "    prefix = ''\n",
    "    if word[0] != aleph_bet[9]:\n",
    "        prefix = prefix + word[0]\n",
    "        if word[1].isalpha() == False:\n",
    "            prefix = prefix + word[1]\n",
    "            if word[2].isalpha() == False:\n",
    "                prefix = prefix + word[2]\n",
    "    no_prefix_word = word[len(prefix):]\n",
    "\n",
    "    if len(prefix) > 0:\n",
    "        yud1 = aleph_bet[9]\n",
    "    else:\n",
    "        yud1 = aleph_bet[9]+vowel[0]\n",
    "\n",
    "    yud2 = aleph_bet[9]+vowel[8]\n",
    "\n",
    "    cant_marks = []\n",
    "\n",
    "    for character in no_prefix_word:\n",
    "        if character in cant:\n",
    "            cant_marks.append(character)\n",
    "    if len(cant_marks) == 0:\n",
    "        new_shem = prefix + yud1 + yud2\n",
    "    elif len(cant_marks) == 1:\n",
    "        new_shem = prefix + yud1 + yud2 + cant_marks[0]\n",
    "    elif len(cant_marks) == 2:\n",
    "        new_shem = prefix + yud1 + cant_marks[0] + yud2 + cant_marks[1]\n",
    "\n",
    "    return new_shem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates new paragraph with double-yud in place of Shem Havaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_shem(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if shem in nonalpha_remover(word):\n",
    "            double_yud = shem_converter(word)\n",
    "            par_list[index] = double_yud\n",
    "\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use https://he.wikisource.org/wiki/%D7%9E%D7%A7%D7%A8%D7%90 for testing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kamatz katan section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_exception(word):\n",
    "    if word[-1] != aleph_bet[12]:\n",
    "        return True\n",
    "    elif aleph_bet[9] in word:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    #returns \"true\" if the word is a likely false positive for the word \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    #Paragraph is now split into words\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if (kal in word or khal in word) and kamatz_exception(word) == False:\n",
    "            split_word = word.split(vowel[8])\n",
    "            word = vowel[20].join(split_word)\n",
    "            par_list[index] = word\n",
    "            #If \"k(h)al\" appears in a word, change it to a kamatz katan\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    #Put paragraph back together\n",
    "    if kol_space in new_par: \n",
    "        new_par_split = new_par.split(kol_space)\n",
    "        new_par = kol_maqqaf.join(new_par_split)\n",
    "    if khol_space in new_par:\n",
    "        new_par_split = new_par.split(khol_space)\n",
    "        new_par = khol_maqqaf.join(new_par_split)\n",
    "    #Previous if-statements swap a space following \"kol\" to a maqqaf\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Puts a maqqaf after \"et\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_fixer(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    if et in par_list:\n",
    "        new_par_split = paragraph.split(space_et_space)\n",
    "        new_paragraph = et_maqqaf.join(new_par_split)\n",
    "        new_par_split = new_paragraph.split(space_ve_et_space)\n",
    "        new_paragraph = ve_et_maqqaf.join(new_par_split)\n",
    "    else:\n",
    "        new_paragraph = paragraph\n",
    "    return new_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run paragraph through all converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_converter(paragraph):\n",
    "    par1 = convert_shem(paragraph)\n",
    "    par2 = kamatz_katan(par1)\n",
    "    par3 = et_fixer(par2)\n",
    "    return par3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'olat_tamid_2.1.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    lines = list(infile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(text_converter(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'olat_tamid_converted.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in new_lines:\n",
    "        if line != '':\n",
    "            if line[-1] != '\\n':\n",
    "                outfile.write(line + '\\n')\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "        else:\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
